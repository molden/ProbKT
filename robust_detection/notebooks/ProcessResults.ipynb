{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15badab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from robust_detection.wandb_config import ENTITY\n",
    "from robust_detection.data_utils.baselines_data_utils import ObjectsCountDataModule\n",
    "from robust_detection.baselines.cnn_model import CNN\n",
    "#from robust_detection.baselines.detection_cnn import objects_detection_cnn\n",
    "from torchmetrics.detection.map import MeanAveragePrecision\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7610b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "api = wandb.Api()\n",
    "\n",
    "results = {}\n",
    "\n",
    "sweep_dict = {\"wps6fgrx\":CNN}\n",
    "model_names = [\"CNN\"]\n",
    "\n",
    "\n",
    "#data_dict = {\"MMSynthetic\":SyntheticMMDataModule, \"Pendulum\":PendulumDataModule, \"CV\":CVDataModule}\n",
    "#data_dict = {\"molecules/mol_labels\":ObjectsCountDataModule}#, \"mnist/alldigits_2\":MNISTCountDataModule,  \"mnist/alldigits_5\":MNISTCountDataModule} #, \\\n",
    "            #\"mnist/alldigits_large\":MNISTCountDataModule, \"mnist/alldigits_2_large\":MNISTCountDataModule,  \"mnist/alldigits_5_large\":MNISTCountDataModule,}\n",
    "#data_dict = {\"Pendulum\":PendulumDataModule}\n",
    "data_dict = {\"clevr/clevr_all\":ObjectsCountDataModule}\n",
    "fold_name = \"fold\"\n",
    "pre_trained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e943013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def find_threshold_number_islands(cam_,nobj):\n",
    "    \n",
    "    MAX_ITERATIONS = 25\n",
    "    sigma = 0\n",
    "    fixed_mean = 0.5\n",
    "    thresh = fixed_mean\n",
    "    \n",
    "    best_thresh = (fixed_mean,0)\n",
    "    \n",
    "    #print(f\"Threshold = :{thresh}\")\n",
    "    try:\n",
    "        num_islands = get_number_islands(cam_,fixed_mean)\n",
    "    except RecursionError:\n",
    "        num_islands = 0\n",
    "        \n",
    "    iter_idx = 0\n",
    "    while num_islands != nobj:\n",
    "        if sigma<0.94:\n",
    "            sigma += 0.05\n",
    "        #thresh+=0.1\n",
    "    \n",
    "        thresh = fixed_mean + np.random.rand()*sigma - sigma/2\n",
    "        try:\n",
    "            num_islands = get_number_islands(cam_,thresh)\n",
    "        except RecursionError:\n",
    "            num_islands = num_islands\n",
    "        #print(\"Num Islands\")\n",
    "        #print(num_islands)\n",
    "        \n",
    "        if np.abs(num_islands-nobj)< np.abs(best_thresh[1]-nobj):\n",
    "            best_thresh = (thresh,num_islands)\n",
    "        \n",
    "        if iter_idx>MAX_ITERATIONS:\n",
    "            break\n",
    "            \n",
    "        iter_idx += 1\n",
    "                \n",
    "    if num_islands == nobj:\n",
    "        return thresh\n",
    "    else:\n",
    "        return best_thresh[0]\n",
    "\n",
    "def get_boxes_from_contour(contours, img):\n",
    "    \n",
    "    boxes = []\n",
    "    scores = []\n",
    "    for item in range(len(contours)):\n",
    "        cnt = contours[item]\n",
    "        if len(cnt)>5:\n",
    "            #print(len(cnt))\n",
    "            x,y,w,h = cv2.boundingRect(cnt) # x, y is the top left corner, and w, h are the width and height respectively\n",
    "            poly_coords = [cnt] # polygon coordinates are based on contours\n",
    "            \n",
    "            boxes.append(torch.Tensor([x,y,x+w,y+h]))\n",
    "            \n",
    "            scores.append(img[:,y:y+h,x:x+w].max())\n",
    "\n",
    "        else: print(\"contour error (too small)\")\n",
    "    return boxes, scores\n",
    "\n",
    "def get_number_islands(cam_array, threshold):\n",
    "    graph = np.zeros_like(cam_array)\n",
    "    graph[cam_array > threshold] = 1\n",
    "    graph[cam_array <= threshold] = 0\n",
    "\n",
    "    class Graph:\n",
    "\n",
    "        def __init__(self, row, col, g):\n",
    "            self.ROW = row\n",
    "            self.COL = col\n",
    "            self.graph = g\n",
    "\n",
    "        # A function to check if a given cell\n",
    "        # (row, col) can be included in DFS\n",
    "        def isSafe(self, i, j, visited):\n",
    "            # row number is in range, column number\n",
    "            # is in range and value is 1\n",
    "            # and not yet visited\n",
    "            return (i >= 0 and i < self.ROW and\n",
    "                    j >= 0 and j < self.COL and\n",
    "                    not visited[i][j] and self.graph[i][j])\n",
    "\n",
    "\n",
    "        # A utility function to do DFS for a 2D\n",
    "        # boolean matrix. It only considers\n",
    "        # the 8 neighbours as adjacent vertices\n",
    "        def DFS(self, i, j, visited):\n",
    "\n",
    "            # These arrays are used to get row and\n",
    "            # column numbers of 8 neighbours\n",
    "            # of a given cell\n",
    "            rowNbr = [-1, -1, -1,  0, 0,  1, 1, 1];\n",
    "            colNbr = [-1,  0,  1, -1, 1, -1, 0, 1];\n",
    "\n",
    "            # Mark this cell as visited\n",
    "            visited[i][j] = True\n",
    "\n",
    "            # Recur for all connected neighbours\n",
    "            for k in range(8):\n",
    "                if self.isSafe(i + rowNbr[k], j + colNbr[k], visited):\n",
    "                    self.DFS(i + rowNbr[k], j + colNbr[k], visited)\n",
    "\n",
    "\n",
    "        # The main function that returns\n",
    "        # count of islands in a given boolean\n",
    "        # 2D matrix\n",
    "        def countIslands(self):\n",
    "            # Make a bool array to mark visited cells.\n",
    "            # Initially all cells are unvisited\n",
    "            visited = [[False for j in range(self.COL)]for i in range(self.ROW)]\n",
    "\n",
    "            # Initialize count as 0 and traverse\n",
    "            # through the all cells of\n",
    "            # given matrix\n",
    "            count = 0\n",
    "            for i in range(self.ROW):\n",
    "                for j in range(self.COL):\n",
    "                    # If a cell with value 1 is not visited yet,\n",
    "                    # then new island found\n",
    "                    if visited[i][j] == False and self.graph[i][j] == 1:\n",
    "                        # Visit all cells in this island\n",
    "                        # and increment island count\n",
    "                        self.DFS(i, j, visited)\n",
    "                        count += 1\n",
    "\n",
    "            return count\n",
    "\n",
    "    row = len(graph)\n",
    "    col = len(graph[0])\n",
    "\n",
    "    g = Graph(row, col, graph)\n",
    "\n",
    "    return(g.countIslands())\n",
    "\n",
    "\n",
    "def get_boxes_single_image(X,y_pred,cam,n_classes = 10):\n",
    "    \"\"\"\n",
    "    cam is the class activation map for all classes\n",
    "    \"\"\"\n",
    "    boxes_img = []\n",
    "    labels_img = []\n",
    "    scores_img = []\n",
    "    for class_i in range(n_classes):\n",
    "        #print(class_i)\n",
    "        \n",
    "        #targets = [ClassifierOutputTarget(class_i)]\n",
    "        #cam_ = cam(input_tensor=X[None,...], targets=targets)\n",
    "        cam_ = cam[class_i]\n",
    "        nobj_pred = y_pred.round()[class_i].detach().long().numpy()\n",
    "\n",
    "        if nobj_pred>0:\n",
    "            \n",
    "            #plt.figure()\n",
    "            #plt.imshow(cam_[0][...,None])\n",
    "            #plt.show()\n",
    "            \n",
    "            thresh = find_threshold_number_islands(cam_[0],nobj_pred)\n",
    "            cam_thresh = np.zeros_like(cam_)\n",
    "            cam_thresh[cam_>thresh]=255\n",
    "            \n",
    "\n",
    "            contours,hierarchy = cv2.findContours(cam_thresh[0].astype(np.uint8), 1, 2)\n",
    "\n",
    "            bbox_coords, scores = get_boxes_from_contour(contours, img = cam_)#, img = cam_thresh.astype(np.uint8))\n",
    "            boxes_img += bbox_coords\n",
    "            labels_img += [class_i]*len(bbox_coords)\n",
    "            scores_img += scores\n",
    "            \n",
    "    return torch.stack(boxes_img), labels_img, scores_img\n",
    "\n",
    "def f(i,X,y_pred,cam_dict,n_classes):\n",
    "    boxes, labels, scores = get_boxes_single_image(X[i].cpu(),y_pred[i].cpu(),cam = [cam_dict[class_i][i][None,...] for class_i in range(n_classes)], n_classes = n_classes)\n",
    "    return(boxes,labels, scores)\n",
    "    \n",
    "def get_cnn_boxes(X,y_pred,cam,n_classes= 10):\n",
    "    #boxes_list = []\n",
    "    #labels_list = []\n",
    "    #scores_list = []\n",
    "    \n",
    "    #print(\"Computing CAM...\")\n",
    "    cam_dict = {class_i:cam(input_tensor=X, targets=[ClassifierOutputTarget(class_i)]*len(X)) for class_i in range(n_classes)}\n",
    "    #print(\"Done\")\n",
    "    \n",
    "    #print(\"Computing boxes...\")\n",
    "    \n",
    "    \n",
    "    X = X.detach().cpu()\n",
    "    y_pred = y_pred.detach().cpu()\n",
    "\n",
    "    from multiprocessing import Pool\n",
    "        \n",
    "    with Pool(15) as p:\n",
    "        res = p.starmap(f,zip([i for i in range(len(X))],[X for _ in range(len(X))],[y_pred for _ in range(len(X))],[cam_dict for _ in range(len(X))],[n_classes for _ in range(len(X))]))\n",
    "        \n",
    "    boxes_list = [b[0] for b in res]\n",
    "    labels_list = [b[1] for b in res]\n",
    "    scores_list = [b[2] for b in res]\n",
    "\n",
    "    #for i in range(len(X)):\n",
    "    #    boxes, labels, scores = get_boxes_single_image(X[i].cpu(),y_pred[i].cpu(),cam = [cam_dict[class_i][i][None,...] for class_i in range(n_classes)], n_classes = n_classes)\n",
    "    #    boxes_list.append(boxes)\n",
    "    #    labels_list.append(labels)\n",
    "    #    scores_list.append(scores)\n",
    "    return boxes_list, labels_list, scores_list\n",
    "\n",
    "\n",
    "def objects_detection_cnn(model,dataloader, single_batch = False):\n",
    "\n",
    "    target_layers = [model.model[1].layer4[-1]]\n",
    "    cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)\n",
    "    boxes_list = []\n",
    "    labels_list = []\n",
    "    scores_list = []\n",
    "    for i,batch in tqdm.tqdm(enumerate(dataloader)):\n",
    "        X,y,_ = batch\n",
    "        y_pred = model(X.to(model.device))\n",
    "\n",
    "        boxes, labels, scores = get_cnn_boxes(X.to(model.device),y_pred,n_classes = y_pred.shape[1], cam = cam)\n",
    "\n",
    "        boxes_list.append(boxes)\n",
    "        labels_list.append(labels)\n",
    "        scores_list.append(scores)\n",
    "        \n",
    "        if single_batch:\n",
    "            break\n",
    "    \n",
    "    return boxes_list, labels_list, scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24627f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1170b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results():\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for i_mod, sweep_name in enumerate(sweep_dict.keys()):\n",
    "\n",
    "        pd_dict = {\"Model\":model_names[i_mod] + \" (MSE)\"}\n",
    "        pd_dict_acc = {\"Model\":model_names[i_mod] + \" (Acc)\"}\n",
    "\n",
    "        model_cls = sweep_dict[sweep_name]\n",
    "        sweep = api.sweep(f\"{ENTITY}/object_detection/{sweep_name}\")\n",
    "\n",
    "        for ood in [False,True]:\n",
    "\n",
    "            pd_dict[\"Type\"] = \"OOD\" if ood else \"In-distribution\"\n",
    "            pd_dict_acc[\"Type\"] = \"OOD\" if ood else \"In-distribution\"\n",
    "\n",
    "            for data_key in data_dict.keys():\n",
    "\n",
    "                best_runs = []\n",
    "                for fold in [0,1,2,3,4]:\n",
    "                    runs_fold = [r for r in sweep.runs if (r.config.get(fold_name)==fold) and (r.config.get(\"data_dir\")==data_key) and (r.config.get(\"pre_trained\")==pre_trained)]\n",
    "                    runs_fold_sorted = sorted(runs_fold,key = lambda run: run.summary.get(\"restored_val_loss\"), reverse = False)\n",
    "                    best_runs.append(runs_fold_sorted[0])\n",
    "\n",
    "                mses = []\n",
    "                accuracies = []\n",
    "                mAPs = []\n",
    "                for run in best_runs:\n",
    "                    fname = [f.name for f in run.files() if \"ckpt\" in f.name][0]\n",
    "                    run.file(fname).download(replace = True, root = \".\")\n",
    "                    model = model_cls.load_from_checkpoint(fname)\n",
    "                    os.remove(fname)\n",
    "\n",
    "                    hparams = dict(model.hparams)\n",
    "\n",
    "                    dataset = data_dict[data_key](**hparams)\n",
    "                    dataset.prepare_data()\n",
    "                    trainer = pl.Trainer(logger = False, gpus = 1)\n",
    "\n",
    "                    if ood:\n",
    "                        preds = trainer.predict(model, dataset.test_ood_dataloader())\n",
    "                    else:\n",
    "                        preds = trainer.predict(model, dataset.test_dataloader())\n",
    "                    Y = torch.cat([pred[\"Y\"] for pred in preds]).cpu()\n",
    "                    Y_hat = torch.cat([pred[\"Y_pred\"] for pred in preds]).cpu()\n",
    "                    M = torch.cat([pred[\"M\"] for pred in preds]).cpu()\n",
    "\n",
    "                    mse = model.compute_mse(Y_hat,Y,M)\n",
    "                    accuracy = model.compute_accuracy(Y,Y_hat,M)\n",
    "                    mses.append(mse)\n",
    "                    accuracies.append(accuracy)\n",
    "\n",
    "                    map_metric = MeanAveragePrecision()\n",
    "\n",
    "                    if ood:\n",
    "                        boxes, labels, scores = objects_detection_cnn(model,dataset.test_ood_dataloader())\n",
    "                    else:\n",
    "                        boxes, labels, scores = objects_detection_cnn(model,dataset.test_dataloader())#, single_batch = True)\n",
    "\n",
    "                    #pred_map_full = [dict(boxes=boxes[i],scores=scores[i],labels=labels[i]) for i in range(len(boxes))]\n",
    "\n",
    "                    #base_idx = 0\n",
    "                    for i_pred,pred in enumerate(preds):\n",
    "                        target_map = [dict(boxes=pred[\"boxes_true\"][i],labels=pred[\"targets\"][i]) for i in range(len(pred[\"targets\"]))]\n",
    "                        pred_map = [dict(boxes=boxes[i_pred][i],scores=torch.Tensor(scores[i_pred][i]),labels=torch.Tensor(labels[i_pred][i])) for i in range(len(boxes[i_pred]))]\n",
    "\n",
    "                        map_metric.update(pred_map,target_map)\n",
    "                        #return map_metric, boxes, labels, scores, pred, target_map, pred_map\n",
    "                        \n",
    "\n",
    "                    mAP = map_metric.compute()\n",
    "                    mAPs.append(mAP[\"map\"])\n",
    "                    print(mAP)\n",
    "\n",
    "\n",
    "                mses = np.array(mses)\n",
    "                mse_mu = mses.mean()\n",
    "                mse_std = mses.std()\n",
    "\n",
    "                accuracies = np.array(accuracies)\n",
    "                acc_mu = accuracies.mean()\n",
    "                acc_std = accuracies.std()\n",
    "\n",
    "                mAPs = np.array(mAPs)\n",
    "                map_mu = mAPs.mean()\n",
    "                map_std = mAPs.std()\n",
    "\n",
    "                mse_str = \"$ \" + str(mse_mu.round(3))+ \"\\pm\" +str(mse_std.round(3)) +\" $\"\n",
    "                acc_str = \"$ \" + str(acc_mu.round(3))+ \"\\pm\" +str(acc_std.round(3)) +\" $\"\n",
    "                map_str = \"$ \" + str(map_mu.round(3))+ \"\\pm\" +str(map_std.round(3)) +\" $\"\n",
    "\n",
    "                pd_dict[data_key] = mse_str\n",
    "                pd_dict_acc[data_key] = acc_str\n",
    "                pd_dict_acc[data_key + \" mAP\"] = map_str\n",
    "\n",
    "            df = df.append(pd_dict,ignore_index =True)\n",
    "            df = df.append(pd_dict_acc,ignore_index =True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bfe51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_metric, boxes, labels, scores, pred, target_map, pred_map = process_results()\n",
    "\n",
    "\n",
    "#map_metric = MeanAveragePrecision()#iou_thresholds = [0.5,0.75])\n",
    "#map_metric.update(pred_map[:2],target_map[:2])\n",
    "#mAP = map_metric.compute()\n",
    "#print(mAP)\n",
    "\n",
    "#import torchvision\n",
    "#import matplotlib.pyplot as plt\n",
    "#img_idx = 3\n",
    "#img_with_boxes = torchvision.utils.draw_bounding_boxes(torch.Tensor(pred[\"X\"][img_idx]).permute(1,2,0).to(torch.uint8).permute(2,0,1),boxes[0][img_idx])\n",
    "#img_with_true_boxes = torchvision.utils.draw_bounding_boxes(torch.Tensor(pred[\"X\"][img_idx]).permute(1,2,0).to(torch.uint8).permute(2,0,1),pred[\"boxes_true\"][img_idx], colors = \"red\")\n",
    "\n",
    "\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(10, 10))\n",
    "#ax.imshow(pred[\"X\"][img_idx].permute(1,2,0) + img_with_boxes.permute(1,2,0).numpy() + img_with_true_boxes.permute(1,2,0).numpy(), interpolation='nearest')\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f38c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a30f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7af9c0f228244dd8ea47411e32433f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:28, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:31, 30.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:59, 29.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [02:55, 28.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [05:20, 29.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [12:36, 29.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [15:00, 28.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': tensor(0.0162), 'map_50': tensor(0.0969), 'map_75': tensor(0.0002), 'map_small': tensor(-1.), 'map_medium': tensor(0.0162), 'map_large': tensor(-1.), 'mar_1': tensor(0.0544), 'mar_10': tensor(0.0592), 'mar_100': tensor(0.0592), 'mar_small': tensor(-1.), 'mar_medium': tensor(0.0592), 'mar_large': tensor(-1.), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07da3ba5922548ecbe182b69012f5dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [06:56, 30.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [12:14, 29.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [14:39, 29.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [15:20, 28.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': tensor(0.0348), 'map_50': tensor(0.1858), 'map_75': tensor(0.0011), 'map_small': tensor(-1.), 'map_medium': tensor(0.0349), 'map_large': tensor(-1.), 'mar_1': tensor(0.0843), 'mar_10': tensor(0.0937), 'mar_100': tensor(0.0937), 'mar_small': tensor(-1.), 'mar_medium': tensor(0.0937), 'mar_large': tensor(-1.), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67c08234cc44ff4ac94835528ed3118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [05:03, 30.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [05:32, 30.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [08:02, 30.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [13:26, 29.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [14:51, 29.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [15:27, 28.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': tensor(0.0262), 'map_50': tensor(0.1438), 'map_75': tensor(0.0015), 'map_small': tensor(-1.), 'map_medium': tensor(0.0263), 'map_large': tensor(-1.), 'mar_1': tensor(0.0696), 'mar_10': tensor(0.0786), 'mar_100': tensor(0.0786), 'mar_small': tensor(-1.), 'mar_medium': tensor(0.0786), 'mar_large': tensor(-1.), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfadcf4ae094cd9b05368618867349c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [04:58, 29.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour error (too small)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [13:20, 29.74s/it]"
     ]
    }
   ],
   "source": [
    "df = process_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e087ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df.Model.str.contains(\"Acc\")].to_latex(escape = False,index= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c885800b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>clevr/clevr_all</th>\n",
       "      <th>clevr/clevr_all mAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN (MSE)</td>\n",
       "      <td>In-distribution</td>\n",
       "      <td>$ 0.003\\pm0.0 $</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN (Acc)</td>\n",
       "      <td>In-distribution</td>\n",
       "      <td>$ 0.97\\pm0.005 $</td>\n",
       "      <td>$ 0.036\\pm0.014 $</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN (MSE)</td>\n",
       "      <td>OOD</td>\n",
       "      <td>$ 0.016\\pm0.001 $</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN (Acc)</td>\n",
       "      <td>OOD</td>\n",
       "      <td>$ 0.831\\pm0.016 $</td>\n",
       "      <td>$ 0.029\\pm0.01 $</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model             Type    clevr/clevr_all clevr/clevr_all mAP\n",
       "0  CNN (MSE)  In-distribution    $ 0.003\\pm0.0 $                 NaN\n",
       "1  CNN (Acc)  In-distribution   $ 0.97\\pm0.005 $   $ 0.036\\pm0.014 $\n",
       "2  CNN (MSE)              OOD  $ 0.016\\pm0.001 $                 NaN\n",
       "3  CNN (Acc)              OOD  $ 0.831\\pm0.016 $    $ 0.029\\pm0.01 $"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35740a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
