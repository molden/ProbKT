{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc9032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from robust_detection.wandb_config import ENTITY\n",
    "from robust_detection.models.detr import DETR\n",
    "from robust_detection.data_utils.rcnn_data_utils import Objects_RCNN\n",
    "from torchmetrics.detection.map import MeanAveragePrecision\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sweep id: s2oaikka\n",
    "#auqg6d50\n",
    "gpu = 0\n",
    "api = wandb.Api()\n",
    "\n",
    "results = {}\n",
    "\n",
    "sweep_dict = {\"08k4u8gp\":DETR}\n",
    "#sweep_dict = {(\"436j7xuk\",\"f9dy36lb\"):DETR}\n",
    "model_names = [\"DETR (Hungarian track)\"]\n",
    "\n",
    "\n",
    "#data_dict = {\"MMSynthetic\":SyntheticMMDataModule, \"Pendulum\":PendulumDataModule, \"CV\":CVDataModule}\n",
    "#data_dict = {\"molecules/mol_labels/\":Objects_RCNN}#, \"mnist/alldigits_2\":MNISTCountDataModule,  \"mnist/alldigits_5\":MNISTCountDataModule} #, \\\n",
    "            #\"mnist/alldigits_large\":MNISTCountDataModule, \"mnist/alldigits_2_large\":MNISTCountDataModule,  \"mnist/alldigits_5_large\":MNISTCountDataModule,}\n",
    "#data_dict = {\"mnist/alldigits_5/\":Objects_RCNN}#, \"mnist/alldigits_2\":MNISTCountDataModule,  \"mnist/alldigits_5\":MNISTCountDataModule} #, \\\n",
    "            #\"mnist/alldigits_large\":MNISTCountDataModule\n",
    "data_dict = {\"molecules/molecules_skip\":Objects_RCNN}\n",
    "\n",
    "fold_name = \"fold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_mod, sweep_name in enumerate(sweep_dict.keys()):\n",
    "#for i_mod, sweep_names in enumerate(sweep_dict.keys()):\n",
    "    #print(sweep_name)\n",
    "    pd_dict_acc = {\"Model\":model_names[i_mod] + \" (Acc)\"}\n",
    "    pd_dict_map = {\"Model\":model_names[i_mod] + \" (mAP)\"}\n",
    "\n",
    "\n",
    "    #model_cls = sweep_dict[sweep_names]\n",
    "    #sweep_runs = []\n",
    "    #for sweep_name in sweep_names:\n",
    "    #    sweep_runs += api.sweep(f\"{ENTITY}/object_detection/{sweep_name}\").runs\n",
    "    model_cls = sweep_dict[sweep_name]\n",
    "    sweep = api.sweep(f\"{ENTITY}/object_detection/{sweep_name}\")\n",
    "\n",
    "    for ood in [False,True]:\n",
    "\n",
    "        pd_dict_acc[\"Type\"] = \"OOD\" if ood else \"In-distribution\"\n",
    "        pd_dict_map[\"Type\"] = \"OOD\" if ood else \"In-distribution\"\n",
    "\n",
    "        \n",
    "        for data_key in data_dict.keys():\n",
    "\n",
    "            best_runs = []\n",
    "            for fold in [0,1,2,3,4]:\n",
    "                #runs_fold = [r for r in sweep_runs if (r.config.get(fold_name)==fold)]\n",
    "                runs_fold = [r for r in sweep.runs if (r.config.get(fold_name)==fold)]\n",
    "                runs_fold_sorted = sorted(runs_fold,key = lambda run: run.summary.get(\"restored_val_acc\"), reverse = True)\n",
    "                best_runs.append(runs_fold_sorted[0])\n",
    "\n",
    "            accuracies = []\n",
    "            mAPs = []\n",
    "            for run in best_runs:\n",
    "                fname = [f.name for f in run.files() if \"ckpt\" in f.name][0]\n",
    "                run.file(fname).download(replace = True, root = \".\")\n",
    "                model = model_cls.load_from_checkpoint(fname)\n",
    "                os.remove(fname)\n",
    "\n",
    "                hparams = dict(model.hparams)\n",
    "                hparams[\"re_train\"] = False\n",
    "                hparams[\"skip_data_path\"]=None\n",
    "                hparams[\"data_path\"]= data_key\n",
    "                dataset = data_dict[data_key](**hparams)\n",
    "                dataset.prepare_data()\n",
    "                trainer = pl.Trainer(logger = False, gpus = 1)\n",
    "\n",
    "                if ood:\n",
    "                    preds = trainer.predict(model, dataset.test_ood_dataloader())\n",
    "                else:\n",
    "                    preds = trainer.predict(model, dataset.test_dataloader())\n",
    "                \n",
    "                Y = []\n",
    "                Y_hat = []\n",
    "                scores = []\n",
    "                boxes = []\n",
    "                idxs = []\n",
    "                map_metric = MeanAveragePrecision()\n",
    "                #print(len(preds))\n",
    "                for pred in preds:\n",
    "                    Y += pred[\"targets\"]\n",
    "                    Y_hat += pred[\"preds\"]\n",
    "                    scores += pred[\"scores\"]\n",
    "                    boxes  += pred[\"boxes\"]\n",
    "                    idxs    += pred[\"idx\"]\n",
    "                    #pred_map = [dict(boxes=pred[\"boxes\"][i],scores=pred[\"scores\"][i],labels=pred[\"preds\"][i]) for i in range(len(pred))]\n",
    "                    #target_map = [dict(boxes=pred[\"boxes_true\"][i],labels=pred[\"targets\"][i]) for i in range(len(pred))]\n",
    "                    #map_metric.update(pred_map,target_map)\n",
    "                    \n",
    "                    pred_map = [dict(boxes=pred[\"boxes\"][i],scores=pred[\"scores\"][i],labels=pred[\"preds\"][i]) for i in range(len(pred[\"targets\"]))]\n",
    "                    target_map = [dict(boxes=pred[\"boxes_true\"][i],labels=pred[\"targets\"][i]) for i in range(len(pred[\"targets\"]))]\n",
    "                    #print(\"preds\")\n",
    "                    #print(pred_map)\n",
    "                    #print(\"targets\")\n",
    "                    #print(target_map)\n",
    "                    map_metric.update(pred_map,target_map)\n",
    "                #print(Y_hat)\n",
    "                #print(len(Y_hat))\n",
    "                mAP = map_metric.compute()\n",
    "                labels = []\n",
    "                new_boxes = []\n",
    "                for i in range(len(Y_hat)):\n",
    "                    keep = [scores[i] > 0.65]\n",
    "                    labels.append(Y_hat[i][keep])\n",
    "                    new_boxes.append(boxes[i][keep])\n",
    "                #print(len(labels))\n",
    "                #print(labels)\n",
    "        #keep = [keep.append([preds[i][\"scores\"] > 0.9]) for i in range(len(targets))]\n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        #preds = torch.Tensor([preds[i][preds[i][\"scores\"] > 0.9] for i in range(len(targets))])\n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        #return torch.Tensor([torch.equal(targets[i][\"labels\"].sort()[0],preds[i][\"labels\"].sort()[0]) for i in range(len(targets)) ]).mean()\n",
    "                keep_correct = [torch.equal(Y[i].sort()[0],labels[i][torch.where(labels[i] != 0)].sort()[0]) for i in range(len(Y)) ]\n",
    "                accuracy = np.array([torch.equal(Y[i].sort()[0],labels[i][torch.where(labels[i] != 0)].sort()[0]) for i in range(len(Y)) ]).mean()\n",
    "                #accuracy = np.array([torch.equal(Y[i].sort()[0],Y_hat[i].sort()[0]) for i in range(len(Y))]).mean()\n",
    "                print(accuracy)\n",
    "                #print(keep_correct)\n",
    "                print(mAP)\n",
    "                count_sulfur=0\n",
    "                id_c = 0\n",
    "                for idx,correct in zip(idxs, keep_correct):\n",
    "        \n",
    "                    if correct:\n",
    "            \n",
    "                       boxs    = new_boxes[id_c]\n",
    "                       b_labels= labels[id_c]\n",
    "                       if 5 in b_labels:\n",
    "                            count_sulfur+=1\n",
    "                    id_c+=1\n",
    "                print(f\"count sulfur in correct image: {count_sulfur}\")\n",
    "                accuracies.append(accuracy)\n",
    "                mAPs.append(mAP[\"map\"])\n",
    "\n",
    "            accuracies = np.array(accuracies)\n",
    "            acc_mu = accuracies.mean()\n",
    "            acc_std = accuracies.std()\n",
    "            \n",
    "            mAPs = np.array(mAPs)\n",
    "            map_mu = mAPs.mean()\n",
    "            map_std = mAPs.std()\n",
    "\n",
    "            acc_str = \"$ \" + str(acc_mu.round(3))+ \"\\pm\" +str(acc_std.round(3)) +\" $\"\n",
    "            map_str = \"$ \" + str(map_mu.round(3))+ \"\\pm\" +str(map_std.round(3)) +\" $\"\n",
    "\n",
    "\n",
    "            pd_dict_acc[data_key] = acc_str\n",
    "            pd_dict_acc[data_key + \" mAP\"] = map_str\n",
    "\n",
    "            print(pd_dict_acc)\n",
    "\n",
    "        df = df.append(pd_dict_acc,ignore_index =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d199dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df.Model.str.contains(\"Acc\")].to_latex(escape = False,index= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4abcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from robust_detection.utils import DATA_DIR\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "count = 0\n",
    "print(len(idxs))\n",
    "print(len(keep_correct))\n",
    "id_c = 0\n",
    "for idx,correct in zip(idxs, keep_correct):\n",
    "        \n",
    "        if correct:\n",
    "            if count == 37:\n",
    "                imagename=f\"{os.path.join(DATA_DIR,dataset.data_path,'test')}/images/{str(idx)}.png\"\n",
    "                boxs    = new_boxes[id_c]\n",
    "                b_labels= labels[id_c]\n",
    "            if 5 in b_labels:\n",
    "                print(f\"silfur in {count}\")\n",
    "            count+=1\n",
    "        id_c+=1\n",
    "print(imagename)\n",
    "print(count)\n",
    "imgcv = cv2.imread(imagename)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "label_dict={0: \"cube_metal_small\",1: \"cube_metal_large\",2: \"cube_rubber_small\",3: \"cube_rubber_large\",4: \"sphere_metal_small\",5: \"sphere_metal_large\",6: \"sphere_rubber_small\",7: \"sphere_rubber_large\",8: \"cylinder_metal_small\",9: \"cylinder_metal_large\",10: \"cylinder_rubber_small\",11: \"cylinder_rubber_large\"}\n",
    "for box,label in zip(boxs,b_labels):\n",
    "    box.cpu().numpy()\n",
    "    print(int(box[0]))\n",
    "    cv2.rectangle(imgcv, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (255,0,0), 2)\n",
    "    cv2.putText(imgcv, str([int(label)-1]), (int(box[0]), int(box[1])), font, 1, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "plt.imshow(imgcv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6b8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
