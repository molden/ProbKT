{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15badab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from robust_detection import wandb_config\n",
    "from robust_detection.models.rcnn import RCNN\n",
    "from robust_detection.data_utils.rcnn_data_utils import Objects_RCNN\n",
    "from torchmetrics.detection.map import MeanAveragePrecision\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "api = wandb.Api()\n",
    "\n",
    "results = {}\n",
    "\n",
    "sweep_dict = {\"abdv8kfl\":RCNN}\n",
    "model_names = [\"RCNN (DPL track)\"]\n",
    "\n",
    "\n",
    "#data_dict = {\"MMSynthetic\":SyntheticMMDataModule, \"Pendulum\":PendulumDataModule, \"CV\":CVDataModule}\n",
    "#data_dict = {\"molecules/mol_labels/\":Objects_RCNN}#, \"mnist/alldigits_2\":MNISTCountDataModule,  \"mnist/alldigits_5\":MNISTCountDataModule} #, \\\n",
    "            #\"mnist/alldigits_large\":MNISTCountDataModule, \"mnist/alldigits_2_large\":MNISTCountDataModule,  \"mnist/alldigits_5_large\":MNISTCountDataModule,}\n",
    "#data_dict = {\"mnist/alldigits_5/\":Objects_RCNN}#, \"mnist/alldigits_2\":MNISTCountDataModule,  \"mnist/alldigits_5\":MNISTCountDataModule} #, \\\n",
    "            #\"mnist/alldigits_large\":MNISTCountDataModule\n",
    "data_dict = {\"molecules/molecules_skip\":Objects_RCNN}\n",
    "\n",
    "fold_name = \"fold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24627f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1170b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_mod, sweep_name in enumerate(sweep_dict.keys()):\n",
    "\n",
    "    pd_dict_acc = {\"Model\":model_names[i_mod] + \" (Acc)\"}\n",
    "    pd_dict_map = {\"Model\":model_names[i_mod] + \" (mAP)\"}\n",
    "\n",
    "\n",
    "    #model_cls = sweep_dict[sweep_names]\n",
    "    #sweep_runs = []\n",
    "    #for sweep_name in sweep_names:\n",
    "    #    sweep_runs += api.sweep(f\"{ENTITY}/object_detection/{sweep_name}\").runs\n",
    "    model_cls = sweep_dict[sweep_name]\n",
    "    sweep = api.sweep(f\"{ENTITY}/object_detection/{sweep_name}\")\n",
    "    sweep_runs = []\n",
    "    sweep_runs += api.sweep(f\"{ENTITY}/object_detection/{sweep_name}\").runs\n",
    "    print(sweep_runs)\n",
    "    for ood in [False,True]:\n",
    "\n",
    "        pd_dict_acc[\"Type\"] = \"OOD\" if ood else \"In-distribution\"\n",
    "        pd_dict_map[\"Type\"] = \"OOD\" if ood else \"In-distribution\"\n",
    "\n",
    "        \n",
    "        for data_key in data_dict.keys():\n",
    "\n",
    "            best_runs = []\n",
    "            for fold in [0,1,2,3,4]:\n",
    "                #runs_fold = [r for r in sweep_runs if (r.config.get(fold_name)==fold) and (r.config.get(\"target_data_path\")==data_key)]\n",
    "                runs_fold = [r for r in sweep_runs if (r.config.get(fold_name)==fold)]\n",
    "                runs_fold_sorted = sorted(runs_fold,key = lambda run: run.summary.get(\"restored_val_acc\"), reverse = True)\n",
    "                best_runs.append(runs_fold_sorted[0])\n",
    "\n",
    "            accuracies = []\n",
    "            mAPs = []\n",
    "            for run in best_runs:\n",
    "                fname = [f.name for f in run.files() if \"ckpt\" in f.name][0]\n",
    "                run.file(fname).download(replace = True, root = \".\")\n",
    "                model = model_cls.load_from_checkpoint(fname)\n",
    "                os.remove(fname)\n",
    "\n",
    "                hparams = dict(model.hparams)\n",
    "                hparams[\"re_train\"] = False\n",
    "                hparams[\"data_path\"]= data_key\n",
    "                dataset = data_dict[data_key](**hparams)\n",
    "                dataset.prepare_data()\n",
    "                trainer = pl.Trainer(logger = False, gpus = 1)\n",
    "\n",
    "                if ood:\n",
    "                    preds = trainer.predict(model, dataset.test_ood_dataloader())\n",
    "                else:\n",
    "                    preds = trainer.predict(model, dataset.test_dataloader())\n",
    "                \n",
    "                Y = []\n",
    "                Y_hat = []\n",
    "                map_metric = MeanAveragePrecision()\n",
    "                for pred in preds:\n",
    "                    Y += pred[\"targets\"]\n",
    "                    Y_hat += pred[\"preds\"]\n",
    "                    \n",
    "                    pred_map = [dict(boxes=pred[\"boxes\"][i],scores=pred[\"scores\"][i],labels=pred[\"preds\"][i]) for i in range(len(pred[\"targets\"]))]\n",
    "                    target_map = [dict(boxes=pred[\"boxes_true\"][i],labels=pred[\"targets\"][i]) for i in range(len(pred[\"targets\"]))]\n",
    "                    map_metric.update(pred_map,target_map)\n",
    "                \n",
    "                mAP = map_metric.compute()\n",
    "                accuracy = np.array([torch.equal(Y[i].sort()[0],Y_hat[i].sort()[0]) for i in range(len(Y))]).mean()\n",
    "                print(accuracy)\n",
    "                print(mAP)\n",
    "\n",
    "                accuracies.append(accuracy)\n",
    "                mAPs.append(mAP[\"map\"])\n",
    "\n",
    "            accuracies = np.array(accuracies)\n",
    "            acc_mu = accuracies.mean()\n",
    "            acc_std = accuracies.std()\n",
    "            \n",
    "            mAPs = np.array(mAPs)\n",
    "            map_mu = mAPs.mean()\n",
    "            map_std = mAPs.std()\n",
    "\n",
    "            acc_str = \"$ \" + str(acc_mu.round(3))+ \"\\pm\" +str(acc_std.round(3)) +\" $\"\n",
    "            map_str = \"$ \" + str(map_mu.round(3))+ \"\\pm\" +str(map_std.round(3)) +\" $\"\n",
    "\n",
    "\n",
    "            pd_dict_acc[data_key] = acc_str\n",
    "            pd_dict_acc[data_key + \" mAP\"] = map_str\n",
    "\n",
    "            print(pd_dict_acc)\n",
    "\n",
    "        df = df.append(pd_dict_acc,ignore_index =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e087ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df.Model.str.contains(\"Acc\")].to_latex(escape = False,index= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4964e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
